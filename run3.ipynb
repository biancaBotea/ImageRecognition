{"cells":[{"cell_type":"markdown","metadata":{"id":"z-2e-Z6oV6hT"},"source":["# Run3"]},{"cell_type":"markdown","metadata":{"id":"hxoQQpkPV6hX"},"source":["Importing the packages"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-12-15T21:50:30.423511Z","iopub.status.busy":"2021-12-15T21:50:30.422848Z","iopub.status.idle":"2021-12-15T21:50:30.431612Z","shell.execute_reply":"2021-12-15T21:50:30.430434Z","shell.execute_reply.started":"2021-12-15T21:50:30.423440Z"},"id":"TIwJUvs-V6hX","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sn; sn.set(font_scale=1.4)\n","from sklearn.utils import shuffle           \n","import matplotlib.pyplot as plt             \n","import cv2                                 \n","import tensorflow as tf                \n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from keras.applications.vgg16 import VGG16\n","from keras.preprocessing import image\n","from keras.applications.vgg16 import preprocess_input\n","from sklearn import decomposition"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T23:23:43.321692Z","iopub.status.busy":"2021-12-15T23:23:43.321188Z","iopub.status.idle":"2021-12-15T23:23:43.327223Z","shell.execute_reply":"2021-12-15T23:23:43.326528Z","shell.execute_reply.started":"2021-12-15T23:23:43.321645Z"},"id":"ZnLcFc1DV6hZ","trusted":true},"outputs":[],"source":["class_names = ['Mountain', 'Street', 'Coast', 'Forest', 'Highway', 'Office', 'OpenCountry', \"bedroom\", 'industrial', 'kitchen', 'livingroom', 'Insidecity', 'store', 'Suburb', 'TallBuilding']\n","class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n","\n","nb_classes = len(class_names)\n","\n","#The images seem to all be in this size but it's better to be sure\n","IMAGE_SIZE = (256, 256)"]},{"cell_type":"markdown","metadata":{"id":"iGIVmfKoV6ha"},"source":["Loading the training data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T21:50:30.446670Z","iopub.status.busy":"2021-12-15T21:50:30.446219Z","iopub.status.idle":"2021-12-15T21:50:30.458872Z","shell.execute_reply":"2021-12-15T21:50:30.456707Z","shell.execute_reply.started":"2021-12-15T21:50:30.446627Z"},"id":"28vBe9u3V6ha","trusted":true},"outputs":[],"source":["def load_data():\n","    datasets = ['../input/training1/training', '../input/training2/training']\n","    output = []\n","    images = []\n","    labels = []\n","    # Iterate through training and test sets\n","    for dataset in datasets:    \n","        print(\"Loading {}\".format(dataset))\n","        \n","        # Iterate through each folder corresponding to a category\n","        for folder in os.listdir(dataset):\n","            label = class_names_label[folder]\n","            \n","            # Iterate through each image in our folder\n","            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n","                \n","                # Get the path name of the image\n","                img_path = os.path.join(os.path.join(dataset, folder), file)\n","                \n","                # Open and resize the img\n","                image = cv2.imread(img_path)\n","                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","                image = cv2.resize(image, IMAGE_SIZE) \n","                \n","                # Append the image and its corresponding label to the output\n","                images.append(image)\n","                labels.append(label)\n","                \n","    images = np.array(images, dtype = 'float32')\n","    labels = np.array(labels, dtype = 'int32')       \n","    output = (images, labels)\n","\n","    return output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T21:50:30.460938Z","iopub.status.busy":"2021-12-15T21:50:30.460324Z","iopub.status.idle":"2021-12-15T21:50:38.629114Z","shell.execute_reply":"2021-12-15T21:50:38.628327Z","shell.execute_reply.started":"2021-12-15T21:50:30.460891Z"},"id":"AsWcbIxhV6hb","trusted":true},"outputs":[],"source":["(images, labels) = load_data()"]},{"cell_type":"markdown","metadata":{"id":"nSUaEYOVV6hc"},"source":["Splitting the data into training set and test set and scaling the data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T21:50:38.630713Z","iopub.status.busy":"2021-12-15T21:50:38.630441Z","iopub.status.idle":"2021-12-15T21:50:40.904008Z","shell.execute_reply":"2021-12-15T21:50:40.903197Z","shell.execute_reply.started":"2021-12-15T21:50:38.630662Z"},"id":"ONw8qeX5V6hd","trusted":true},"outputs":[],"source":["train_images,test_images,train_labels,test_labels =train_test_split(images,labels,test_size=0.2)\n","train_images, train_labels = shuffle(train_images, train_labels, random_state=42)\n","train_images = train_images / 255.0 \n","test_images = test_images / 255.0"]},{"cell_type":"markdown","metadata":{"id":"gp3EcUN7V6hd"},"source":["Extracting features from VGG16."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T21:50:40.905917Z","iopub.status.busy":"2021-12-15T21:50:40.905564Z","iopub.status.idle":"2021-12-15T21:50:41.607469Z","shell.execute_reply":"2021-12-15T21:50:41.606469Z","shell.execute_reply.started":"2021-12-15T21:50:40.905843Z"},"id":"OLorECuCV6he","trusted":true},"outputs":[],"source":[" vgg = VGG16(weights='imagenet', include_top=False)"]},{"cell_type":"markdown","metadata":{"id":"TxjV9hD0V6he"},"source":["Get features from VGG16"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T21:50:41.609244Z","iopub.status.busy":"2021-12-15T21:50:41.608965Z","iopub.status.idle":"2021-12-15T22:01:42.574166Z","shell.execute_reply":"2021-12-15T22:01:42.573187Z","shell.execute_reply.started":"2021-12-15T21:50:41.609178Z"},"id":"hv4G3SbNV6he","trusted":true},"outputs":[],"source":["# tf.keras.applications.vgg16.preprocess_input(train_images)\n","# tf.keras.applications.vgg16.preprocess_input(test_images)\n","train_features = vgg.predict(train_images)\n","test_features = vgg.predict(test_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T22:01:42.575727Z","iopub.status.busy":"2021-12-15T22:01:42.575426Z","iopub.status.idle":"2021-12-15T22:01:42.580235Z","shell.execute_reply":"2021-12-15T22:01:42.579389Z","shell.execute_reply.started":"2021-12-15T22:01:42.575666Z"},"id":"6Dt61wOlV6hf","trusted":true},"outputs":[],"source":["n_train, x, y, z = train_features.shape\n","n_test, x, y, z = test_features.shape\n","numFeatures = x * y * z"]},{"cell_type":"markdown","metadata":{"id":"ITHyc2QcV6hf"},"source":["Visualising the data with principal componen analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T22:01:42.581818Z","iopub.status.busy":"2021-12-15T22:01:42.581455Z","iopub.status.idle":"2021-12-15T22:01:45.058158Z","shell.execute_reply":"2021-12-15T22:01:45.057449Z","shell.execute_reply.started":"2021-12-15T22:01:42.581774Z"},"id":"PiKuZmKxV6hf","trusted":true},"outputs":[],"source":["pca = decomposition.PCA(n_components = 2) #this way I can draw it on a 2D plot\n","\n","X = train_features.reshape((n_train, x*y*z))\n","pca.fit(X)\n","\n","C = pca.transform(X) \n","C1 = C[:,0]\n","C2 = C[:,1]\n","\n","plt.subplots(figsize=(10,10))\n","\n","for i, class_name in enumerate(class_names):\n","    plt.scatter(C1[train_labels == i][:1000], C2[train_labels == i][:1000], label = class_name, alpha=0.4)\n","plt.legend()\n","plt.title(\"PCA Projection\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"nqIolwisV6hg"},"source":["Seems like clustering may not be enough.\n","Training a single neural network on top of the obtained features\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T22:01:45.059791Z","iopub.status.busy":"2021-12-15T22:01:45.059316Z","iopub.status.idle":"2021-12-15T22:01:53.676287Z","shell.execute_reply":"2021-12-15T22:01:53.675234Z","shell.execute_reply.started":"2021-12-15T22:01:45.059744Z"},"id":"iZzD0-LCV6hg","trusted":true},"outputs":[],"source":["model2 = tf.keras.Sequential([\n","    tf.keras.layers.Flatten(input_shape = (x, y, z)),\n","    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n","    tf.keras.layers.Dense(15, activation=tf.nn.softmax)\n","])\n","\n","model2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","history = model2.fit(train_features, train_labels, batch_size=64, epochs=20, validation_split = 0.2) #batch size was 128  before"]},{"cell_type":"markdown","metadata":{"id":"u9ku5hFUV6hg"},"source":["We should get approximately 0.844 accuracy (+0.1 accuracy) over the simple ConvNet."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T22:01:53.678161Z","iopub.status.busy":"2021-12-15T22:01:53.677833Z","iopub.status.idle":"2021-12-15T22:01:53.731096Z","shell.execute_reply":"2021-12-15T22:01:53.730421Z","shell.execute_reply.started":"2021-12-15T22:01:53.678099Z"},"id":"zFL5ei-sV6hg","trusted":true},"outputs":[],"source":["test_loss = model2.evaluate(test_features, test_labels)"]},{"cell_type":"markdown","metadata":{"id":"r-wZB8m2V6hh"},"source":["^0.59 accuracy"]},{"cell_type":"markdown","metadata":{"id":"sfLNXoTnV6hh"},"source":["# Ensemble Neural Networks"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T22:01:53.732826Z","iopub.status.busy":"2021-12-15T22:01:53.732385Z","iopub.status.idle":"2021-12-15T22:01:53.737179Z","shell.execute_reply":"2021-12-15T22:01:53.736380Z","shell.execute_reply.started":"2021-12-15T22:01:53.732754Z"},"id":"r7RUt114V6hh","trusted":true},"outputs":[],"source":["np.random.seed(seed=42)\n","# Number of estimators\n","n_estimators = 10\n","# Proporition of samples to use to train each training\n","max_samples = 0.8\n","\n","max_samples *= n_train\n","max_samples = int(max_samples)"]},{"cell_type":"markdown","metadata":{"id":"n8d7GvdLV6hh"},"source":["We define n_estimators Neural Networks. \n","\n","Each Neural Network will be trained on random subsets of the training dataset. Each subset contains max_samples samples."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T22:01:53.738770Z","iopub.status.busy":"2021-12-15T22:01:53.738261Z","iopub.status.idle":"2021-12-15T22:01:55.576014Z","shell.execute_reply":"2021-12-15T22:01:55.574868Z","shell.execute_reply.started":"2021-12-15T22:01:53.738723Z"},"id":"SlJ2aMRlV6hi","trusted":true},"outputs":[],"source":["models = list()\n","random = np.random.randint(50, 100, size = n_estimators)\n","\n","for i in range(n_estimators):\n","    \n","    # Model\n","    model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape = (x, y, z)),\n","                                # One layer with random size\n","                                    tf.keras.layers.Dense(random[i], activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(random[i] + 10,activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(random[i]- 10,activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(15, activation=tf.nn.softmax)\n","                                ])\n","    \n","    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n","    \n","    # Store model\n","    models.append(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T22:01:55.577821Z","iopub.status.busy":"2021-12-15T22:01:55.577542Z","iopub.status.idle":"2021-12-15T22:02:44.356788Z","shell.execute_reply":"2021-12-15T22:02:44.355769Z","shell.execute_reply.started":"2021-12-15T22:01:55.577761Z"},"id":"nbknyZqNV6hi","trusted":true},"outputs":[],"source":["histories = []\n","\n","for i in range(n_estimators):\n","    # Train each model on a bag of the training data\n","    train_idx = np.random.choice(len(train_features), size = max_samples)\n","    histories.append(models[i].fit(train_features[train_idx], train_labels[train_idx], batch_size=10, epochs=30, validation_split = 0.1))"]},{"cell_type":"markdown","metadata":{"id":"1P8iappEV6hi"},"source":["We aggregate each model individual predictions to form a final prediction."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T22:02:44.359475Z","iopub.status.busy":"2021-12-15T22:02:44.359040Z","iopub.status.idle":"2021-12-15T22:02:47.221061Z","shell.execute_reply":"2021-12-15T22:02:47.219927Z","shell.execute_reply.started":"2021-12-15T22:02:44.359407Z"},"id":"ZOnT01-WV6hi","trusted":true},"outputs":[],"source":["predictions = []\n","for i in range(n_estimators):\n","    predictions.append(models[i].predict(test_features))\n","    \n","predictions = np.array(predictions)\n","predictions = predictions.sum(axis = 0)\n","pred_labels = predictions.argmax(axis=1)"]},{"cell_type":"markdown","metadata":{"id":"AlpjQAb6V6hi"},"source":["We should improve our result as we have a lower variance."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T22:02:47.223225Z","iopub.status.busy":"2021-12-15T22:02:47.222857Z","iopub.status.idle":"2021-12-15T22:02:47.229743Z","shell.execute_reply":"2021-12-15T22:02:47.228497Z","shell.execute_reply.started":"2021-12-15T22:02:47.223150Z"},"id":"i2_wxR6ZV6hj","trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","print(\"Accuracy : {}\".format(accuracy_score(test_labels, pred_labels)))"]},{"cell_type":"markdown","metadata":{"id":"-soVdISCV6hj"},"source":["Loading the test data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T22:31:26.838525Z","iopub.status.busy":"2021-12-15T22:31:26.838170Z","iopub.status.idle":"2021-12-15T22:31:41.075885Z","shell.execute_reply":"2021-12-15T22:31:41.074917Z","shell.execute_reply.started":"2021-12-15T22:31:26.838477Z"},"id":"V1kp52SyV6hj","trusted":true},"outputs":[],"source":["folder ='../input/testing/testing'\n","testing_images = []\n","image_names = []\n","# Iterate through test images\n","            \n","# Iterate through each image in our folder\n","for file in tqdm(os.listdir(folder)):\n","                \n","    # Get the path name of the image\n","    img_path = os.path.join(folder, file)\n","                \n","    # Open and resize the img\n","    test_image = cv2.imread(img_path)\n","    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n","    test_image = cv2.resize(test_image, IMAGE_SIZE) \n","    \n","    #add image to testing images\n","    testing_images.append(test_image)\n","    image_names.append(file)\n","                \n","testing_images = np.array(testing_images, dtype = 'float32')"]},{"cell_type":"markdown","metadata":{"id":"BEO_ce4NV6hj"},"source":["Extracting features from testing images and making predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T22:37:16.915630Z","iopub.status.busy":"2021-12-15T22:37:16.915252Z","iopub.status.idle":"2021-12-15T22:58:54.510827Z","shell.execute_reply":"2021-12-15T22:58:54.509778Z","shell.execute_reply.started":"2021-12-15T22:37:16.915561Z"},"id":"hIq-zfBHV6hj","trusted":true},"outputs":[],"source":["features = vgg.predict(testing_images)\n","\n","predictions = []\n","for i in range(n_estimators):\n","    predictions.append(models[i].predict(features))\n","    \n","predictions = np.array(predictions)\n","predictions = predictions.sum(axis = 0)\n","pred_labels = predictions.argmax(axis=1)"]},{"cell_type":"markdown","metadata":{"id":"KdNwgeiZV6hj"},"source":["Writing predictions to the .txt file"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T22:58:54.513020Z","iopub.status.busy":"2021-12-15T22:58:54.512695Z","iopub.status.idle":"2021-12-15T22:58:54.523091Z","shell.execute_reply":"2021-12-15T22:58:54.522246Z","shell.execute_reply.started":"2021-12-15T22:58:54.512957Z"},"id":"jinjx0itV6hk","trusted":true},"outputs":[],"source":["result = zip(image_names, pred_labels) #is this correct? Maybe (Update - it works!)\n","f = open('./run3.txt', 'w')\n","for name, label in result:\n","    f.write(name + ' ' + class_names[label])\n","    f.write('\\n')\n","f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T23:23:53.261632Z","iopub.status.busy":"2021-12-15T23:23:53.261079Z","iopub.status.idle":"2021-12-15T23:23:53.268973Z","shell.execute_reply":"2021-12-15T23:23:53.267898Z","shell.execute_reply.started":"2021-12-15T23:23:53.261585Z"},"id":"MPZS5PtCV6hk","trusted":true},"outputs":[],"source":["for name in image_names:\n","    print(class_l)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"comp-vision-run3.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
